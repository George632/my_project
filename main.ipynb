{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-08-21T21:56:44.856047Z",
     "end_time": "2023-08-21T21:56:44.877788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed element: 5\n",
      "Updated list: [1, 2, 3, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "# 创建一个示例列表\n",
    "import os\n",
    "\n",
    "my_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "# 使用 pop() 方法删除并返回最后一个元素\n",
    "removed_element = my_list.pop()\n",
    "my_list.append(7)\n",
    "\n",
    "# 打印删除的元素和更新后的列表\n",
    "print(\"Removed element:\", removed_element)\n",
    "print(\"Updated list:\", my_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): SimpleModule(\n",
      "    (linear): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      "  (1): SimpleModule(\n",
      "    (linear): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      "  (2): SimpleModule(\n",
      "    (linear): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "# 定义一个简单的模块\n",
    "class SimpleModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModule, self).__init__()\n",
    "        self.linear = nn.Linear(10, 10)\n",
    "\n",
    "# 创建一个包含N个相同模块的ModuleList\n",
    "N = 3\n",
    "module = SimpleModule()\n",
    "module_list = nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "# 打印模块列表\n",
    "print(module_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T21:56:44.878790Z",
     "end_time": "2023-08-21T21:56:45.686637Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 4\n",
      "Parameter name: linear.in_proj_weight, Shape: torch.Size([120, 40])\n",
      "Parameter name: linear.in_proj_bias, Shape: torch.Size([120])\n",
      "Parameter name: linear.out_proj.weight, Shape: torch.Size([40, 40])\n",
      "Parameter name: linear.out_proj.bias, Shape: torch.Size([40])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModule, self).__init__()\n",
    "        self.linear = nn.MultiheadAttention(40, 4, dropout=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# 创建模块实例\n",
    "module = SimpleModule()\n",
    "\n",
    "# 获取模块中需要优化的参数\n",
    "parameters = list(module.parameters())\n",
    "print(\"Number of parameters:\", len(parameters))\n",
    "\n",
    "# 打印每个参数的形状\n",
    "for name, param in module.named_parameters():\n",
    "    print(f\"Parameter name: {name}, Shape: {param.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T21:56:45.686637Z",
     "end_time": "2023-08-21T21:56:45.705797Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 40])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "\n",
    "# 创建输入示例\n",
    "input_q = torch.randn(10, 20, 40)\n",
    "input_k = torch.randn(10, 20, 40)\n",
    "input_v = torch.randn(10, 20, 40)\n",
    "\n",
    "# 创建 MultiheadAttention 模块\n",
    "multihead_attention = nn.MultiheadAttention(40, 4, dropout=0.1)\n",
    "\n",
    "# 使用 make_dot 输出计算图\n",
    "output, _ = multihead_attention(input_q, input_k, input_v)\n",
    "print(output.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T21:56:45.701747Z",
     "end_time": "2023-08-21T21:56:45.839248Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero tensor:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Normalized tensor:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建一个示例全零张量\n",
    "zero_tensor = torch.zeros(3, 3)\n",
    "\n",
    "# 打印原始全零张量\n",
    "print(\"Zero tensor:\")\n",
    "print(zero_tensor)\n",
    "\n",
    "# 使用 nn.LayerNorm 进行归一化\n",
    "layer_norm = nn.LayerNorm(normalized_shape=zero_tensor.size()[1:])\n",
    "normalized_tensor = layer_norm(zero_tensor)\n",
    "\n",
    "# 打印归一化后的张量\n",
    "print(\"Normalized tensor:\")\n",
    "print(normalized_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T21:56:45.842249Z",
     "end_time": "2023-08-21T21:56:45.854776Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1992, -0.1266, -0.0129,  0.0329, -0.0862],\n",
      "        [ 0.1992, -0.1266, -0.0129,  0.0329, -0.0862],\n",
      "        [ 0.1992, -0.1266, -0.0129,  0.0329, -0.0862]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.linear_layer = nn.Linear(in_features=10, out_features=5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.linear_layer(x)\n",
    "        return output\n",
    "\n",
    "# 创建模型实例\n",
    "model = MyModel()\n",
    "\n",
    "# 创建一个全零的输入张量\n",
    "input_tensor = torch.zeros(3, 10)\n",
    "\n",
    "# 进行前向传播\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T21:56:45.857607Z",
     "end_time": "2023-08-21T21:56:45.882632Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T21:56:45.872623Z",
     "end_time": "2023-08-21T21:56:45.886644Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked tensor:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Shape: tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建示例张量\n",
    "tensor1 = torch.tensor([1, 2, 3])\n",
    "tensor2 = torch.tensor([4, 5, 6])\n",
    "tensor3 = torch.tensor([7, 8, 9])\n",
    "\n",
    "# 将张量堆叠成新的张量\n",
    "stacked_tensor = torch.stack([tensor1, tensor2, tensor3])\n",
    "\n",
    "print(\"Stacked tensor:\")\n",
    "print(stacked_tensor)\n",
    "print(\"Shape:\", stacked_tensor[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T21:56:45.890644Z",
     "end_time": "2023-08-21T21:56:45.902655Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "type2class = {\n",
    "            \"cabinet\": 0,\n",
    "            \"bed\": 1,\n",
    "            \"chair\": 2,\n",
    "            \"sofa\": 3,\n",
    "            \"table\": 4,\n",
    "            \"door\": 5,\n",
    "            \"window\": 6,\n",
    "            \"bookshelf\": 7,\n",
    "            \"picture\": 8,\n",
    "            \"counter\": 9,\n",
    "            \"desk\": 10,\n",
    "            \"curtain\": 11,\n",
    "            \"refrigerator\": 12,\n",
    "            \"showercurtrain\": 13,\n",
    "            \"toilet\": 14,\n",
    "            \"sink\": 15,\n",
    "            \"bathtub\": 16,\n",
    "            \"garbagebin\": 17,\n",
    "        }\n",
    "class2type = {type2class[t]: t for t in type2class}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T21:56:45.904661Z",
     "end_time": "2023-08-21T21:56:45.923952Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cabinet\n",
      "bed\n",
      "chair\n",
      "sofa\n",
      "table\n",
      "door\n",
      "window\n",
      "bookshelf\n",
      "picture\n",
      "counter\n",
      "desk\n",
      "curtain\n",
      "refrigerator\n",
      "showercurtrain\n",
      "toilet\n",
      "sink\n",
      "bathtub\n",
      "garbagebin\n"
     ]
    }
   ],
   "source": [
    "for t in type2class:\n",
    "    print(t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T21:56:45.921449Z",
     "end_time": "2023-08-21T21:56:45.936631Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nyu40ids = np.array(\n",
    "            [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39]\n",
    "        )\n",
    "nyu40id2class = {\n",
    "    nyu40id: i for i, nyu40id in enumerate(list(nyu40ids))\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T21:56:45.938629Z",
     "end_time": "2023-08-21T21:56:45.953690Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{3: 0,\n 4: 1,\n 5: 2,\n 6: 3,\n 7: 4,\n 8: 5,\n 9: 6,\n 10: 7,\n 11: 8,\n 12: 9,\n 14: 10,\n 16: 11,\n 24: 12,\n 28: 13,\n 33: 14,\n 34: 15,\n 36: 16,\n 39: 17}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyu40id2class"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T21:56:45.954694Z",
     "end_time": "2023-08-21T21:56:45.966480Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import argparse\n",
    "from utils import config\n",
    "def make_args_parser():\n",
    "    parser = argparse.ArgumentParser(\"Wireframe Reconstruction Using Transformers\", add_help=False)\n",
    "\n",
    "    # Config\n",
    "    parser.add_argument('--config', default='./config/config/WFTR.yaml', type=str, help='config file')\n",
    "\n",
    "    # Training\n",
    "    parser.add_argument(\"--start_epoch\", default=-1, type=int)\n",
    "    parser.add_argument(\"--max_epoch\", default=720, type=int)\n",
    "    parser.add_argument(\"--eval_every_epoch\", default=10, type=int)\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "\n",
    "    # Testing\n",
    "    parser.add_argument(\"--test_only\", default=False, action=\"store_true\")\n",
    "    parser.add_argument(\"--test_ckpt\", default=None, type=str)\n",
    "\n",
    "    # I/O\n",
    "    parser.add_argument(\"--checkpoint_dir\", default=None, type=str)\n",
    "    parser.add_argument(\"--log_every\", default=10, type=int)\n",
    "    parser.add_argument(\"--log_metrics_every\", default=20, type=int)\n",
    "    parser.add_argument(\"--save_separate_checkpoint_every_epoch\", default=100, type=int)\n",
    "\n",
    "    # Distributed Training\n",
    "    parser.add_argument(\"--ngpus\", default=1, type=int)\n",
    "    parser.add_argument(\"--dist_url\", default=\"tcp://localhost:12345\", type=str)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    assert args.config is not None\n",
    "    cfg = config.load_yaml_config(args.config)\n",
    "    args = config.merge_args_cfg(args, cfg)\n",
    "    return args\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-23T21:12:16.873914Z",
     "end_time": "2023-08-23T21:12:16.887439Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: Wireframe Reconstruction Using Transformers [--config CONFIG]\n",
      "                                                   [--start_epoch START_EPOCH]\n",
      "                                                   [--max_epoch MAX_EPOCH]\n",
      "                                                   [--eval_every_epoch EVAL_EVERY_EPOCH]\n",
      "                                                   [--seed SEED] [--test_only]\n",
      "                                                   [--test_ckpt TEST_CKPT]\n",
      "                                                   [--checkpoint_dir CHECKPOINT_DIR]\n",
      "                                                   [--log_every LOG_EVERY]\n",
      "                                                   [--log_metrics_every LOG_METRICS_EVERY]\n",
      "                                                   [--save_separate_checkpoint_every_epoch SAVE_SEPARATE_CHECKPOINT_EVERY_EPOCH]\n",
      "                                                   [--ngpus NGPUS]\n",
      "                                                   [--dist_url DIST_URL]\n",
      "Wireframe Reconstruction Using Transformers: error: unrecognized arguments: -f C:\\Users\\12617\\AppData\\Roaming\\jupyter\\runtime\\kernel-a4a20070-3967-4dd4-a449-e203898dc856.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[1;31mSystemExit\u001B[0m\u001B[1;31m:\u001B[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3468: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "make_args_parser()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- Done !!! -----------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*35, 'Done !!!', \"-\"*35)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T23:04:46.228049Z",
     "end_time": "2023-08-21T23:04:46.233154Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtensorboard\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SummaryWriter\n\u001B[0;32m      2\u001B[0m writer \u001B[38;5;241m=\u001B[39m SummaryWriter(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mZCH_Tensorboard_Trying_logs\u001B[39m\u001B[38;5;124m\"\u001B[39m)      \u001B[38;5;66;03m#第一个参数指明 writer 把summary内容 写在哪个目录下\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m100\u001B[39m):\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdistutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversion\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LooseVersion\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(tensorboard, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__version__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m LooseVersion(\n\u001B[0;32m      5\u001B[0m     tensorboard\u001B[38;5;241m.\u001B[39m__version__\n\u001B[0;32m      6\u001B[0m ) \u001B[38;5;241m<\u001B[39m LooseVersion(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1.15\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorboard'"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"ZCH_Tensorboard_Trying_logs\")      #第一个参数指明 writer 把summary内容 写在哪个目录下\n",
    "\n",
    "for i in range(100):\n",
    "    writer.add_scalar(\"y=x\",i,i)\n",
    "\n",
    "for i in range(100):\n",
    "    writer.add_scalar(\"y=2*x\",2*i,i)\n",
    "\n",
    "\n",
    "writer.close()     #将event log写完之后，记得close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "time_str = datetime.now()\n",
    "time_str = time_str.strftime('%d-%m-%Y-%Hh-%Mm-%Ss')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-22T14:09:46.963978Z",
     "end_time": "2023-08-22T14:09:46.971566Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22-08-2023-14h-09m-46s\n"
     ]
    }
   ],
   "source": [
    "print(time_str)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-22T14:09:48.264004Z",
     "end_time": "2023-08-22T14:09:48.287123Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 已知信息\n",
    "center_point = np.array([1.0, 2.0, 3.0])\n",
    "direction_vector = np.array([0.5, 0.5, 0.5])  # 方向向量可以是单位向量或非单位向量\n",
    "segment_length = 2.0\n",
    "\n",
    "# 计算半段长度\n",
    "half_segment_length = segment_length / 2\n",
    "\n",
    "# 计算线段的两个端点\n",
    "endpoint1 = center_point - half_segment_length * direction_vector\n",
    "endpoint2 = center_point + half_segment_length * direction_vector\n",
    "\n",
    "print(\"Endpoint 1:\", endpoint1)\n",
    "print(\"Endpoint 2:\", endpoint2)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.6569, 8.4853],\n",
      "        [2.8284, 5.6569]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建两个示例张量\n",
    "x = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "y = torch.tensor([[5.0, 6.0], [7.0, 8.0]])\n",
    "\n",
    "# 计算两个张量之间的欧氏距离\n",
    "distances = torch.cdist(x, y)\n",
    "\n",
    "print(distances)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-01T18:08:54.756080Z",
     "end_time": "2023-09-01T18:08:54.769112Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is (B,W,H): torch.Size([2, 7680, 3]) torch.Size([2, 870, 3])\n",
      "Hausdorff Distance is: torch.Size([2, 256, 29])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def torch2D_Hausdorff_distance(x,y): # Input be like (Batch,width,height)\n",
    "    distance_matrix = torch.cdist(x,y,p=2) # p=2 means Euclidean Distance\n",
    "    distance_matrix = distance_matrix.view(2, 256, 29, 30, -1)\n",
    "\n",
    "    value1 = distance_matrix.min(-1)[0].max(-1, keepdim=True)[0]\n",
    "    value2 = distance_matrix.min(-2)[0].max(-1, keepdim=True)[0]\n",
    "\n",
    "    value = torch.cat((value1, value2), dim=-1)\n",
    "\n",
    "    return value.max(-1)[0]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    u = torch.rand( 2,256 * 30, 3)\n",
    "\n",
    "    v = torch.rand( 2, 29 * 30, 3)\n",
    "\n",
    "    print(\"Input shape is (B,W,H):\", u.shape, v.shape)\n",
    "    HD = torch2D_Hausdorff_distance(u,v)\n",
    "    print(\"Hausdorff Distance is:\", HD.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-01T18:09:01.130056Z",
     "end_time": "2023-09-01T18:09:01.168337Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 30, 3])\n",
      "(1, 2, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 假设输入张量的形状为 (B, N, 2, 3)\n",
    "B = 1  # 批量大小\n",
    "N = 2  # 线段数量\n",
    "num_samples = 30  # 采样点数\n",
    "\n",
    "# 随机生成输入张量\n",
    "input_tensor = torch.rand(B, N, 2, 3)\n",
    "# input_tensor[0,1,:,:] = input_tensor[0,0,:,:] + 0.05\n",
    "# 提取起点和终点\n",
    "start_points = input_tensor[:, :, 0, :]  # 形状为 (B, N, 3)\n",
    "end_points = input_tensor[:, :, 1, :]    # 形状为 (B, N, 3)\n",
    "\n",
    "# 生成等间隔的采样权重\n",
    "weights = torch.linspace(0, 1, num_samples, device=input_tensor.device).view(1, 1, num_samples, 1)\n",
    "\n",
    "# 插值计算采样点\n",
    "sampled_points = start_points.unsqueeze(2) + weights * (end_points.unsqueeze(2) - start_points.unsqueeze(2))\n",
    "\n",
    "print(sampled_points.shape)  # 输出采样点的形状 (B, N, num_samples, 3)\n",
    "points = sampled_points.to(torch.float32).numpy()\n",
    "print(points.shape)\n",
    "# print(points[0,0,:,:])\n",
    "# np.savetxt(r'C:\\Users\\shangfeng\\Desktop\\line1.txt', points[0,0,:,:])\n",
    "# np.savetxt(r'C:\\Users\\shangfeng\\Desktop\\line2.txt', points[0,1,:,:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-01T18:09:06.757180Z",
     "end_time": "2023-09-01T18:09:06.767196Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is (B,W,H): torch.Size([1, 1, 30, 3]) torch.Size([1, 1, 30, 3])\n",
      "torch.Size([1, 1, 1, 30, 30])\n",
      "torch.Size([1, 1, 1, 1])\n",
      "torch.Size([1, 1, 1, 1])\n",
      "Hausdorff Distance is: tensor([[[[0.6274]]]])\n"
     ]
    }
   ],
   "source": [
    "def torch2D_Hausdorff_distance(x,y): # Input be like (Batch,width,height)\n",
    "    distance_matrix = torch.cdist(x,y,p=2) # p=2 means Euclidean Distance\n",
    "    distance_matrix = distance_matrix.view(1, 1, 1, 30, -1) # B, N, M, 30, 30\n",
    "    print(distance_matrix.shape)\n",
    "\n",
    "    value1 = distance_matrix.min(-1)[0].max(-1, keepdim=True)[0]\n",
    "    value2 = distance_matrix.min(-2)[0].max(-1, keepdim=True)[0]\n",
    "    print(value1.shape)\n",
    "    print(value2.shape)\n",
    "\n",
    "    value = torch.cat((value1, value2), dim=-1)\n",
    "\n",
    "    return value.max(-1, keepdim=True)[0]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    u = sampled_points[:,0,:,:]\n",
    "    u = u.unsqueeze(1)\n",
    "    v = sampled_points[:, 1, :, :]\n",
    "    v = v.unsqueeze(1)\n",
    "    print(\"Input shape is (B,W,H):\", u.shape, v.shape)\n",
    "    HD = torch2D_Hausdorff_distance(u,v)\n",
    "    print(\"Hausdorff Distance is:\", HD)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-01T18:09:14.336436Z",
     "end_time": "2023-09-01T18:09:14.355605Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([0.6087, 0.3658])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设有两个批次，每个批次包含两个向量\n",
    "batch_size = 2\n",
    "vector_dim = 3\n",
    "\n",
    "# 随机生成示例输入张量\n",
    "input_tensor = torch.rand(batch_size, 2, 2, vector_dim)\n",
    "\n",
    "# 提取每个批次的向量 A 和 B\n",
    "A = input_tensor[:, 0, :]  # 第一个向量\n",
    "B = -input_tensor[:, 1, :]  # 第二个向量\n",
    "print(A.shape)\n",
    "\n",
    "# 计算余弦相似度\n",
    "dot_product = torch.sum(A * B, dim=1)  # 批次内的点积\n",
    "norm_A = torch.norm(A, dim=1)  # 批次内的范数\n",
    "norm_B = torch.norm(B, dim=1)  # 批次内的范数\n",
    "\n",
    "cosine_similarity = abs(dot_product / (norm_A * norm_B))\n",
    "\n",
    "print(1-cosine_similarity)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-01T18:09:19.660994Z",
     "end_time": "2023-09-01T18:09:19.670517Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3])\n",
      "tensor([[[0.6087]],\n",
      "\n",
      "        [[0.3658]]])\n"
     ]
    }
   ],
   "source": [
    "A = A.unsqueeze(1)\n",
    "B = B.unsqueeze(1)\n",
    "norm_A = torch.norm(A, dim=2, keepdim=True)  # (B, N, 1)\n",
    "norm_B = torch.norm(B, dim=2, keepdim=True)  # (B, M, 1)\n",
    "print(A.shape)\n",
    "# 计算余弦相似度\n",
    "# 首先计算所有向量的范数\n",
    "# norms = torch.norm(input_tensor, dim=2, keepdim=True)  # 沿着最后一个维度计算范数\n",
    "# 然后计算点积\n",
    "dot_products = torch.einsum('bni,bmi->bnm', A, B)\n",
    "# 最后计算余弦相似度\n",
    "cosine_similarity = abs(dot_products / (norm_A * norm_B.permute(0, 2, 1)))\n",
    "\n",
    "print(1-cosine_similarity)  # 输出余弦相似度的形状 (batch_size, num_vectors, num_vectors)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-01T18:09:25.285762Z",
     "end_time": "2023-09-01T18:09:25.299299Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设有张量A和B，维度为 (B, N, 3) 和 (B, M, 3)\n",
    "B, N, M = 2, 3, 4\n",
    "A = torch.randn(B, N, 3)\n",
    "B = torch.randn(B, M, 3)\n",
    "\n",
    "# 计算余弦相似性\n",
    "# 计算A和B的范数\n",
    "norm_A = torch.norm(A, dim=2, keepdim=True)  # (B, N, 1)\n",
    "norm_B = torch.norm(B, dim=2, keepdim=True)  # (B, M, 1)\n",
    "\n",
    "# 计算点积\n",
    "dot_product = torch.matmul(A, B.permute(0, 2, 1))  # (B, N, M)\n",
    "\n",
    "# 计算余弦相似性\n",
    "cosine_similarity = dot_product / (norm_A * norm_B.permute(0, 2, 1))  # (B, N, M)\n",
    "\n",
    "print(cosine_similarity.shape)  # 输出余弦相似性的形状 (B, N, M)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-01T18:09:30.821108Z",
     "end_time": "2023-09-01T18:09:30.876101Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected batch2_sizes[0] == bs && batch2_sizes[1] == contraction_size to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_2967/3074782815.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;31m# 计算余弦相似度\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;31m# 使用矩阵乘法扩展到所有组合\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m \u001B[0mcosine_similarity\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mA_normalized\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mB_normalized\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected batch2_sizes[0] == bs && batch2_sizes[1] == contraction_size to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设有张量 A 和 B，分别具有形状 (B, N, 3) 和 (B, M, 3)\n",
    "B = 2  # 批量大小\n",
    "N = 3  # 张量 A 中的线段数量\n",
    "M = 4  # 张量 B 中的线段数量\n",
    "vector_dim = 3  # 向量维度\n",
    "\n",
    "# 随机生成示例数据（用于演示）\n",
    "A = torch.randn(B, N, vector_dim)\n",
    "B = torch.randn(B, M, vector_dim)\n",
    "\n",
    "# 归一化向量\n",
    "A_normalized = torch.nn.functional.normalize(A, dim=2, p=2)\n",
    "B_normalized = torch.nn.functional.normalize(B, dim=2, p=2)\n",
    "\n",
    "# 计算余弦相似度\n",
    "# 使用矩阵乘法扩展到所有组合\n",
    "cosine_similarity = torch.matmul(A_normalized.unsqueeze(2), B_normalized.unsqueeze(1))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5774, 0.5774, 0.5774],\n",
      "        [0.5774, 0.5774, 0.5774]])\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3333, 0.3333, 0.3333]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 示例数据\n",
    "A = torch.tensor([[1.0, 1.0, 1.0], [1.0, 1.0, 1.0]])\n",
    "\n",
    "# 归一化到单位长度（使用L2范数）\n",
    "A_normalized_l2 = torch.nn.functional.normalize(A, dim=1, p=2)\n",
    "print(A_normalized_l2)\n",
    "\n",
    "# 归一化到单位长度（使用L1范数）\n",
    "A_normalized_l1 = torch.nn.functional.normalize(A, dim=1, p=1)\n",
    "print(A_normalized_l1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-01T18:09:44.846732Z",
     "end_time": "2023-09-01T18:09:44.855459Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 3]) torch.Size([2, 5, 3])\n",
      "tensor([[[2.3898, 2.4138, 0.8050, 3.8793, 2.9558],\n",
      "         [2.4292, 0.9984, 3.0394, 1.3057, 1.2865],\n",
      "         [1.7631, 1.5905, 1.5212, 2.8727, 2.4993],\n",
      "         [1.6842, 2.2480, 2.7217, 3.0582, 3.3788],\n",
      "         [1.3688, 2.7979, 3.8400, 3.4825, 3.6855]],\n",
      "\n",
      "        [[3.6133, 1.4335, 1.1342, 0.6100, 2.5234],\n",
      "         [3.7264, 4.0614, 4.5351, 4.7194, 3.3268],\n",
      "         [0.7689, 2.1716, 2.4532, 3.4262, 1.9457],\n",
      "         [1.4715, 1.2789, 1.5387, 2.6069, 1.5580],\n",
      "         [3.5846, 1.7368, 1.6570, 1.2015, 2.4930]]])\n",
      "tensor([[[2.3898, 2.4138, 0.8050, 3.8793, 2.9558],\n",
      "         [2.4292, 0.9984, 3.0394, 1.3057, 1.2865],\n",
      "         [1.7631, 1.5905, 1.5212, 2.8727, 2.4993],\n",
      "         [1.6842, 2.2480, 2.7217, 3.0582, 3.3788],\n",
      "         [1.3688, 2.7979, 3.8400, 3.4825, 3.6855]],\n",
      "\n",
      "        [[3.6133, 1.4335, 1.1342, 0.6100, 2.5234],\n",
      "         [3.7264, 4.0614, 4.5351, 4.7194, 3.3268],\n",
      "         [0.7689, 2.1716, 2.4532, 3.4262, 1.9457],\n",
      "         [1.4715, 1.2789, 1.5387, 2.6069, 1.5580],\n",
      "         [3.5846, 1.7368, 1.6570, 1.2015, 2.4930]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设张量 A 具有形状 B*N*20*3\n",
    "# 假设张量 B 具有形状 B*M*20*3\n",
    "B = 2  # 批量大小\n",
    "N = 3  # N 维度大小\n",
    "M = 4  # M 维度大小\n",
    "vector_dim = 3  # 向量维度\n",
    "\n",
    "# 创建示例张量 A 和 B\n",
    "A = torch.randn(B, N, 5, vector_dim)\n",
    "B1 = torch.randn(B, M, 5, vector_dim)\n",
    "\n",
    "C = A[:, 0, :, :]\n",
    "D = B1[:, 0, :, :]\n",
    "print(C.shape, D.shape)\n",
    "print(torch.cdist(C, D, p=2))\n",
    "# 将张量 A 和 B 展平为形状为 (B*N*20, 3) 和 (B*M*20, 3) 的张量\n",
    "A_flat = A.view(2, -1, 3)\n",
    "B_flat = B1.view(2, -1, 3)\n",
    "\n",
    "# 使用 torch.cdist 计算距离（例如欧几里得距离）\n",
    "# p 参数为 2 表示欧几里得距离\n",
    "distances = torch.cdist(A_flat, B_flat, p=2)\n",
    "\n",
    "print(distances.view(2, 3, 5, 4, 5).transpose(2, 3)[:,0,0,:,:])  # 输出距离张量的形状 (B*N*20, B*M*20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def cosine_similarity_between_segments(segments1, segments2):\n",
    "    \"\"\"\n",
    "    计算两组线段之间的余弦相似度\n",
    "\n",
    "    参数:\n",
    "    segments1 (torch.Tensor): 形状为 (B, N, 2, 3) 的张量，表示第一组线段的两个端点\n",
    "    segments2 (torch.Tensor): 形状为 (B, M, 2, 3) 的张量，表示第二组线段的两个端点\n",
    "\n",
    "    返回:\n",
    "    similarity (torch.Tensor): 形状为 (B, N, M) 的张量，表示每对线段之间的余弦相似度\n",
    "    \"\"\"\n",
    "    B, N, _, _ = segments1.shape\n",
    "    _, M, _, _ = segments2.shape\n",
    "\n",
    "    # 提取每个线段的两个端点\n",
    "    start1 = segments1[:, :, 0, :]  # 形状为 (B, N, 3)\n",
    "    end1 = segments1[:, :, 1, :]\n",
    "\n",
    "    start2 = segments2[:, :, 0, :]  # 形状为 (B, M, 3)\n",
    "    end2 = segments2[:, :, 1, :]\n",
    "\n",
    "    # 计算第一组线段的方向向量\n",
    "    direction1 = end1 - start1  # 形状为 (B, N, 3)\n",
    "\n",
    "    # 计算第二组线段的方向向量\n",
    "    direction2 = end2 - start2  # 形状为 (B, M, 3)\n",
    "\n",
    "    # 归一化方向向量\n",
    "    direction1_norm = torch.nn.functional.normalize(direction1, dim=2)\n",
    "    direction2_norm = torch.nn.functional.normalize(direction2, dim=2)\n",
    "\n",
    "    # 计算余弦相似度矩阵\n",
    "    similarity = torch.bmm(direction1_norm, direction2_norm.permute(0, 2, 1))  # 形状为 (B, N, M)\n",
    "\n",
    "    return similarity\n",
    "\n",
    "# 示例用法\n",
    "B = 2  # 批量大小\n",
    "N = 3  # 第一组线段数量\n",
    "M = 4  # 第二组线段数量\n",
    "segments1 = torch.randn(B, N, 2, 3)\n",
    "segments2 = torch.randn(B, M, 2, 3)\n",
    "\n",
    "similarity = cosine_similarity_between_segments(segments1, segments2)\n",
    "print(similarity.shape)  # 输出余弦相似度矩阵的形状"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type double but found float",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_10995/3007311776.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[0msegments2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mB\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mM\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m \u001B[0msimilarity\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcosine_similarity_between_segments\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msegments1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msegments2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msimilarity\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 输出余弦相似度矩阵的形状\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_10995/3007311776.py\u001B[0m in \u001B[0;36mcosine_similarity_between_segments\u001B[0;34m(segments1, segments2)\u001B[0m\n\u001B[1;32m     32\u001B[0m     \u001B[0;31m# 防止除零错误\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m     \u001B[0mepsilon\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1e-6\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 34\u001B[0;31m     \u001B[0mnorm1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwhere\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnorm1\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mepsilon\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepsilon\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnorm1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     35\u001B[0m     \u001B[0mnorm2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwhere\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnorm2\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mepsilon\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepsilon\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnorm2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: expected scalar type double but found float"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def cosine_similarity_between_segments(segments1, segments2):\n",
    "    \"\"\"\n",
    "    计算两组线段之间的余弦相似度\n",
    "\n",
    "    参数:\n",
    "    segments1 (torch.Tensor): 形状为 (B, N, 2, 3) 的张量，表示第一组线段的两个端点\n",
    "    segments2 (torch.Tensor): 形状为 (B, M, 2, 3) 的张量，表示第二组线段的两个端点\n",
    "\n",
    "    返回:\n",
    "    similarity (torch.Tensor): 形状为 (B, N, M) 的张量，表示每对线段之间的余弦相似度\n",
    "    \"\"\"\n",
    "    # 提取每个线段的两个端点\n",
    "    start1 = segments1[:, :, 0, :]  # 形状为 (B, N, 3)\n",
    "    end1 = segments1[:, :, 1, :]    # 形状为 (B, N, 3)\n",
    "\n",
    "    start2 = segments2[:, :, 0, :]  # 形状为 (B, M, 3)\n",
    "    end2 = segments2[:, :, 1, :]    # 形状为 (B, M, 3)\n",
    "\n",
    "    # 计算第一组线段的方向向量\n",
    "    direction1 = end1 - start1  # 形状为 (B, N, 3)\n",
    "\n",
    "    # 计算第二组线段的方向向量\n",
    "    direction2 = end2 - start2  # 形状为 (B, M, 3)\n",
    "\n",
    "    # 计算余弦相似度\n",
    "    dot_product = torch.einsum('bni,bmi->bnm', direction1, direction2)  # 形状为 (B, N, M)\n",
    "    norm1 = torch.norm(direction1, dim=-1)  # 形状为 (B, N)\n",
    "    norm2 = torch.norm(direction2, dim=-1)  # 形状为 (B, M)\n",
    "\n",
    "    # 防止除零错误\n",
    "    epsilon = 1e-6\n",
    "    norm1 = torch.where(norm1 < epsilon, epsilon, norm1)\n",
    "    norm2 = torch.where(norm2 < epsilon, epsilon, norm2)\n",
    "\n",
    "    similarity = dot_product / (norm1.unsqueeze(2) * norm2.unsqueeze(1))  # 形状为 (B, N, M)\n",
    "\n",
    "    return similarity\n",
    "\n",
    "# 示例用法\n",
    "B = 2  # 批量大小\n",
    "N = 3  # 第一组线段数量\n",
    "M = 4  # 第二组线段数量\n",
    "segments1 = torch.randn(B, N, 2, 3)\n",
    "segments2 = torch.randn(B, M, 2, 3)\n",
    "\n",
    "similarity = cosine_similarity_between_segments(segments1, segments2)\n",
    "print(similarity.shape)  # 输出余弦相似度矩阵的形状"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [6],\n",
      "        [8]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个示例输入张量\n",
    "input = torch.tensor([[1, 2, 3],\n",
    "                      [4, 5, 6],\n",
    "                      [7, 8, 9]])\n",
    "\n",
    "# 创建一个索引张量，指定要在第 1 维度上收集的索引\n",
    "index = torch.tensor([[0],\n",
    "                      [2],\n",
    "                      [1]])\n",
    "\n",
    "# 使用 torch.gather 从 input 中收集指定位置的值\n",
    "output = torch.gather(input, 1, index)\n",
    "\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4806, grad_fn=<NllLossBackward0>)\n",
      "tensor([[ 0.4550,  0.5073, -0.2978,  2.3917,  0.5695],\n",
      "        [ 0.4003,  0.1979,  0.5506, -0.8764, -0.6519],\n",
      "        [ 0.2486, -1.1681, -0.6212, -0.1841, -1.6479]], requires_grad=True)\n",
      "tensor([2, 3, 2])\n",
      "tensor([[-0.0399, -1.2654,  1.0844,  0.5724, -0.7414],\n",
      "        [ 0.1755,  0.8239, -1.5127, -0.6490, -0.4658],\n",
      "        [-1.0944, -1.6821, -1.1379,  0.4537, -1.5439]], requires_grad=True)\n",
      "tensor([[0.4945, 0.0937, 0.1502, 0.0988, 0.1628],\n",
      "        [0.2132, 0.1725, 0.1446, 0.2531, 0.2166],\n",
      "        [0.2461, 0.1893, 0.0986, 0.4154, 0.0506]])\n"
     ]
    }
   ],
   "source": [
    "# Example of target with class indices\n",
    "import torch.nn.functional as F\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randint(5, (3,), dtype=torch.int64)\n",
    "loss = F.cross_entropy(input, target)\n",
    "print(loss)\n",
    "print(input)\n",
    "print(target)\n",
    "# >>> loss.backward()\n",
    "# >>> # Example of target with class probabilities\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "# >>> loss = F.cross_entropy(input, target)\n",
    "# >>> loss.backward()\n",
    "print(input)\n",
    "print(target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6943, -1.8080],\n",
      "        [-1.6374,  1.9197],\n",
      "        [-2.6542,  0.5151]], requires_grad=True)\n",
      "tensor([[0.6340, 0.8597],\n",
      "        [0.4793, 0.4414],\n",
      "        [0.7615, 0.5990]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn((3, 2), requires_grad=True)\n",
    "target = torch.rand((3, 2), requires_grad=False)\n",
    "loss = F.binary_cross_entropy(F.sigmoid(input), target)\n",
    "print(input)\n",
    "print(target)\n",
    "# >>> loss.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (256) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_10995/3369924533.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;31m# 使用 F.binary_cross_entropy 计算二元交叉熵损失\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbinary_cross_entropy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweights\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mreduction\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"mean\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mbinary_cross_entropy\u001B[0;34m(input, target, weight, size_average, reduce, reduction)\u001B[0m\n\u001B[1;32m   2910\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2911\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mweight\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2912\u001B[0;31m         \u001B[0mnew_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_infer_size\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2913\u001B[0m         \u001B[0mweight\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexpand\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnew_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2914\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (256) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# # 创建示例预测和目标标签\n",
    "# predictions = torch.tensor([0.8, 0.2, 0.6, 0.3])  # 模型的预测概率值（sigmoid 函数的输出）\n",
    "# targets = torch.tensor([1, 0, 0, 0], dtype=torch.float32)  # 真实标签，1 表示前景，0 表示背景\n",
    "predictions = torch.rand(2, 256)  # 模型的预测概率值（sigmoid 函数的输出）\n",
    "targets = torch.zeros(2, 256)  # 真实标签，1 表示前景，0 表示背景\n",
    "indices = torch.randperm(256)[:17]\n",
    "targets[0, indices] = 1\n",
    "weights = torch.ones(1, 2) * 0.2\n",
    "weights[0, indices] = 1\n",
    "\n",
    "# 使用 F.binary_cross_entropy 计算二元交叉熵损失\n",
    "loss = F.binary_cross_entropy(predictions, targets, weights,reduction=\"mean\")\n",
    "\n",
    "print(loss)\n",
    "print(F.binary_cross_entropy(predictions, targets))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1730)\n"
     ]
    }
   ],
   "source": [
    "def FocalLoss(predictions, targets, alpha, gamma):\n",
    "    # 计算二元交叉熵损失\n",
    "    bce_loss = F.binary_cross_entropy(predictions, targets, reduction='none')\n",
    "\n",
    "    # 计算预测概率值\n",
    "    p_t = torch.exp(-bce_loss)\n",
    "\n",
    "    # 计算 Focal Loss\n",
    "    focal_loss = alpha * (1 - p_t)**gamma * bce_loss\n",
    "\n",
    "    return focal_loss.mean()\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 创建示例预测和目标标签\n",
    "# predictions = torch.rand(1, 256)  # 模型的预测概率值（sigmoid 函数的输出）\n",
    "# targets = torch.zeros(1, 100)  # 真实标签，1 表示前景，0 表示背景\n",
    "# indices = torch.randperm(100)[:2]\n",
    "# targets[0, indices] = 1\n",
    "# 定义 Focal Loss 的参数\n",
    "alpha = 0.25  # 正样本的权重\n",
    "gamma = 2.0   # 调整因子\n",
    "\n",
    "# 使用 Focal Loss 计算损失\n",
    "loss = FocalLoss(predictions, targets, alpha, gamma)\n",
    "\n",
    "print(loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100])\n",
      "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 1.,  ..., 1., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 1.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 1., 0., 1.],\n",
      "        [0., 0., 1.,  ..., 1., 0., 1.]])\n",
      "Weighted Binary Cross-Entropy Loss: 0.4759114384651184\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 示例数据\n",
    "B = 32  # 批量大小\n",
    "N = 100  # 样本数量\n",
    "# 随机生成模拟的预测值 logits 和相应的标签 targets\n",
    "logits = torch.randn(B, N)\n",
    "print(logits.shape)\n",
    "targets = torch.randint(0, 2, (B, N), dtype=torch.float32)  # 随机生成二分类标签\n",
    "print(targets)\n",
    "\n",
    "# 计算损失\n",
    "# 将正样本的权重设置为1，负样本的权重设置为0.2\n",
    "weights = torch.where(targets == 1, torch.tensor(1.0), torch.tensor(0.2))\n",
    "loss = F.binary_cross_entropy_with_logits(logits, targets, weight=weights, reduction='mean')\n",
    "\n",
    "print(\"Weighted Binary Cross-Entropy Loss:\", loss.item())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "test = {}\n",
    "print(test.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "test['qwe'] = (20*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'qwe': 2000}\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics {'qwe': 2000}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Metrics {test}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ap_calculator'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_18862/2627922732.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0msys\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'utils'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0map_calculator\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mAPCalculator\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m class2type = {0: \"cabinet\",\n\u001B[1;32m      5\u001B[0m             \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m\"bed\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'ap_calculator'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('utils')\n",
    "from ap_calculator import APCalculator\n",
    "class2type = {0: \"cabinet\",\n",
    "            1: \"bed\",\n",
    "            2: \"chair\"}\n",
    "ap_calculator = APCalculator(\n",
    "        dataset_config={},\n",
    "        ap_iou_thresh=[0.25, 0.5],\n",
    "        class2type_map=class2type,\n",
    "        exact_eval=False,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3)\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 示例输入数组\n",
    "input_array = np.array([[[1, 2, 3], [4, 5, 6]],\n",
    "                        [[1, 2, 3], [7, 8, 9]],\n",
    "                        [[4, 5, 6], [1, 2, 3]],\n",
    "                        [[7, 8, 9], [1, 2, 3]]])\n",
    "\n",
    "# 将输入数组展平成形状为 (n*2, 3) 的二维数组\n",
    "flattened_array = input_array.reshape(-1, 3)\n",
    "print(flattened_array.shape)\n",
    "\n",
    "# 使用 np.unique 去除重复的行\n",
    "unique_rows = np.unique(flattened_array, axis=0)\n",
    "\n",
    "# 将结果重新组织成形状为 (n, 2, 3) 的数组\n",
    "result_array = unique_rows\n",
    "\n",
    "print(result_array)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, -1}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_21985/576762284.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m300\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;31m# 计算每个簇的中心点\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "# 创建示例数据集\n",
    "np.random.seed(4)\n",
    "n_samples = 300\n",
    "data = np.random.rand(n_samples, 3) * 2 - 1\n",
    "\n",
    "# 创建DBSCAN模型并设置参数\n",
    "eps = 0.3\n",
    "min_samples = 2\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "\n",
    "# 拟合数据并获取聚类标签\n",
    "labels = dbscan.fit_predict(data)\n",
    "print(set(labels))\n",
    "index = labels.reshape(300, 1)\n",
    "# print(index.type)\n",
    "\n",
    "# 计算每个簇的中心点\n",
    "unique_labels = set(labels) - {-1}  # 去除噪声点的标签\n",
    "cluster_centers = []\n",
    "# print(unique_labels.dtype)\n",
    "\n",
    "for label in unique_labels:\n",
    "    cluster_mask = (labels == label)\n",
    "    if sum(cluster_mask) > 3:\n",
    "        print(True)\n",
    "    cluster_data = data[cluster_mask]\n",
    "    cluster_center = np.mean(cluster_data, axis=0)\n",
    "    cluster_centers.append(cluster_center)\n",
    "\n",
    "print(len(cluster_centers))\n",
    "# 输出每个簇的中心点\n",
    "# for i, center in enumerate(cluster_centers):\n",
    "#\n",
    "#     print(f\"Cluster {i+1} Center:\", center)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True False]\n",
      "[[1 9]\n",
      " [3 4]\n",
      " [7 8]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建示例数组\n",
    "arr = np.array([[1, 9],\n",
    "                [3, 4],\n",
    "                [-1, 6],\n",
    "                [7, 8]])\n",
    "\n",
    "# 找到包含 -1 的行的索引\n",
    "rows_to_delete = np.any(arr == -1, axis=1)\n",
    "\n",
    "# 删除包含 -1 的行\n",
    "filtered_arr = arr[~rows_to_delete]\n",
    "print(rows_to_delete)\n",
    "# 输出删除后的数组\n",
    "print(filtered_arr)\n",
    "# print(set(arr))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3\n"
     ]
    }
   ],
   "source": [
    "def fu(a, b):\n",
    "    a = b\n",
    "    return 0\n",
    "\n",
    "a = 1\n",
    "b=3\n",
    "fu(a, b)\n",
    "print(a, b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建一个空的数组（形状为 (0, 3) 的空数组，表示0行3列）\n",
    "empty_array = np.empty((0, 3))\n",
    "\n",
    "# 创建其他数组\n",
    "array1 = np.array([[1, 2, 3]])\n",
    "array2 = np.array([[4, 5, 6]])\n",
    "\n",
    "# 拼接数组1到空数组\n",
    "empty_array = np.concatenate((empty_array, array1), axis=0)\n",
    "\n",
    "# 拼接数组2到空数组\n",
    "empty_array = np.concatenate((empty_array, array2), axis=0)\n",
    "\n",
    "# empty_array 现在包含了数组1和数组2的内容\n",
    "print(empty_array)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_29470/1017299191.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[0;31m# 在数组A中查找与数组B中的三维点匹配的索引\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[0mpoint\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mB\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mj\u001B[0m\u001B[0;34m]\u001B[0m  \u001B[0;31m# 获取数组B中的三维点\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwhere\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mA\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mpoint\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m  \u001B[0;31m# 查找匹配的索引\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m         \u001B[0mpoint_indices\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0mindex_array\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpoint_indices\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIndexError\u001B[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 示例数组 A 和 B\n",
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "B = np.array([[[1, 2, 3], [4, 5, 6]], [[1, 2, 3], [7, 8, 9]], [[4, 5, 6], [7, 8, 9]]])\n",
    "\n",
    "# 创建一个空列表来存储匹配的索引对\n",
    "matches = []\n",
    "\n",
    "# 遍历数组 B 中的元素，查找与数组 A 中的元素匹配的索引对\n",
    "for i, b_pair in enumerate(B):\n",
    "    for j, a in enumerate(A):\n",
    "        if np.array_equal(b_pair[0], a) or np.array_equal(b_pair[1], a):\n",
    "            matches.append((i, j))\n",
    "\n",
    "# 打印匹配的索引对\n",
    "for match in matches:\n",
    "    print(\"B[{}] 匹配到 A[{}]\".format(match[0], match[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [1 2]\n",
      " [2 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设 label_edges 和 l_corners 的示例数据如下，你需要替换成你的实际数据\n",
    "label_edges = np.array([[[1, 2, 3], [4, 5, 6]],\n",
    "                        [[4, 5, 6], [7, 8, 9]],\n",
    "                        [[7, 8, 9], [1, 2, 3]]])\n",
    "\n",
    "all_vertices = label_edges.reshape(-1, 3)\n",
    "l_corners = np.unique(all_vertices, axis=0)\n",
    "\n",
    "# 创建一个空的 label_index 数组，用于保存结果\n",
    "label_index = []\n",
    "\n",
    "# 遍历 label_edges 中的每个元素\n",
    "for edge in label_edges:\n",
    "    indices = []\n",
    "    for point in edge:\n",
    "        # 使用 np.where 查找匹配的位置并返回索引\n",
    "        matching_indices = np.where((l_corners == point).all(axis=1))[0]\n",
    "        if len(matching_indices) > 0:\n",
    "            indices.append(matching_indices[0])\n",
    "        else:\n",
    "            indices.append(-1)  # 如果没有匹配的点，可以使用 -1 表示\n",
    "\n",
    "    label_index.append(indices)\n",
    "\n",
    "# 将 label_index 转换为 NumPy 数组\n",
    "label_index = np.array(label_index)\n",
    "\n",
    "# 打印 label_index\n",
    "print(label_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3]\n",
      " [2 4]\n",
      " [2 5]\n",
      " [1 6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设n*2的数组示例数据如下，你需要替换成你的实际数据\n",
    "data = np.array([[3, 1],\n",
    "                 [2, 4],\n",
    "                 [5, 2],\n",
    "                 [1, 6]])\n",
    "\n",
    "# 使用 numpy.sort 对每一组进行排序\n",
    "sorted_data = np.sort(data, axis=1)\n",
    "\n",
    "# 打印排序后的数组\n",
    "print(sorted_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'test'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_30566/640566044.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mcollections\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mOrderedDict\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mz\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOrderedDict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mz\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'test'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m: 'test'"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "z = OrderedDict()\n",
    "z['test'] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05_all_average_corner_offset: \n"
     ]
    }
   ],
   "source": [
    "# strs = 'as'\n",
    "import numpy as np\n",
    "a = np.array(0.05)\n",
    "print('%s_all_average_corner_offset: ' % (a))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_30566/2196219283.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0ma\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'-------------------------- '\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0ma\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m' ------------------------------'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "a = str(0.2)\n",
    "print('-------------------------- ' + a + ' ------------------------------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/WFTR/data/Entry-level/train_1/xyz/3.xyz\n",
      "/workspace/WFTR/data/Entry-level/train_1/xyz/2.xyz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "data_dir = '/workspace/WFTR/data/Entry-level/train_1/xyz'\n",
    "out_dir = '/workspace/WFTR/data/Entry-level/train/xyz'\n",
    "for file in os.listdir(data_dir):\n",
    "    out_file = os.path.join(out_dir, file)\n",
    "    xyz_file = os.path.join(data_dir, file)\n",
    "    xyz = np.loadtxt(xyz_file, dtype=np.float64)\n",
    "    if not xyz[0,7] < 100:\n",
    "        xyz[:, 7] = xyz[:, 7] / 65536.0\n",
    "    else:\n",
    "        print(xyz_file)\n",
    "    np.savetxt(out_file, xyz, fmt='%f')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "data_dir = '/workspace/WFTR/data/Entry-level/test_1/xyz'\n",
    "out_dir = '/workspace/WFTR/data/Entry-level/test/xyz'\n",
    "for file in os.listdir(data_dir):\n",
    "    out_file = os.path.join(out_dir, file)\n",
    "    xyz_file = os.path.join(data_dir, file)\n",
    "    xyz = np.loadtxt(xyz_file, dtype=np.float64)\n",
    "    if not xyz[0,7] < 100:\n",
    "        xyz[:, 7] = xyz[:, 7] / 65536.0\n",
    "    else:\n",
    "        print(xyz_file)\n",
    "    np.savetxt(out_file, xyz, fmt='%f')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5767,  1.9179, -0.1612])\n",
      "tensor(1.7155, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.randn(3, requires_grad=False)\n",
    "loss = F.binary_cross_entropy_with_logits(input, target)\n",
    "print(target)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5767,  1.9179, -0.1612])\n",
      "tensor(1.7155, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "# input = torch.randn((3, 2), requires_grad=True)\n",
    "# target = torch.rand((3, 2), requires_grad=False)\n",
    "loss = F.binary_cross_entropy(F.sigmoid(input), target)\n",
    "print(target)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}